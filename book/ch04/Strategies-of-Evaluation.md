# 计算的策略
计算这一部分也是实现解释器过程中变化最多的部分，无论哪一种语言的实现。当计算源代码的时候，有很多不同的策略可以供选择。在本书简单介绍解释器架构的时候，我已经提示到这一点，现在我们手上已经有了抽象语法树（AST），现在问题来了，接下来我们需要做些什么，如何去计算这一棵树？我们接下来看看不同的观点。

在开始之前，值得注意的是解释器和编译器的界限是非常模糊的。常常来讲，解释器通常不离开可执行的环境（与此相关，编译器则脱离可执行环境）它并没有哪些现实中高优化的编程语言那么快。

就跟之前说的，显而易见经典的处理抽象语法树的方法就是解释它，遍历整个语法树，访问树种的每一个节点，并且计算出每一个节点的意义如：输出字符串，加两个数字，执行一个函数内部，等等如此。解释器这样工作的方式也叫“树的遍历”，这也是解释器的原型。有时在计算的过程中也做一些进一步优化处理，来重写抽象语法树（比如移除未使用的变量）或者将其改变成另一种中间形式的表达，对于递归或者循环等计算非常适用。

其他解释器同样遍历整个抽象语法树，与解释抽象语法树本身不同，它们首先将其转换成字节码。字节码同样也是抽象语法树的中间表达形式。这个特定的格式代码各式各样，主要取决于前段和宿主的编程语言。这种中间代码与汇编语言非常相似，可以打赌每一个字节码的定义中包含的 `push` 和 `pop` 等相关的栈操作数。但是字节码并不是原生的机器码，或者汇编语言。它不能被操作系统执行，CPU 也不是解释运行。它仅仅能够被虚拟机解释，这也是一个解释器，就跟 VMWare 和 VirtualBox 一样模拟真正的机器和CPU。虚拟机模式一个能理解这个特定格式的字节码的机器，这种处理方式能够提供一个很好的性能上的优势。

这种策略的变化一点也不影响抽象语法树，除了构建一个语法树，然后解析器直接生成字节码，那么是否现在我们仍然在讨论解释器或者编译器？难道生成字节码然后解释它（或许应该叫做执行）不是编译的一种形式？我想说的是：解释器和编译器之间的界线非常模糊，甚至令人感到糊涂。这样去想：一些编程语言的实现过程是这样的解析源代码，构建抽象语法树，然后将抽象语法树转变成字节码。但是不是在虚拟机上执行相关字节码的相关的操作，而是虚拟机将字节码编译成原生的机器码，仅仅是在执行之前，这种方式叫做 `JIT`解释器或者编译器。

其他编译器或者解释器跳过编程成字节码，它们递归地遍历整个抽象语法树，但是在执行一个特定的分支的所有节点之前将其编译成原生机器码，然后执行，同样也叫做 `JIT`。

一个微小的变种就是一种混合模式，解释器递归的遍历抽象语法树，只有当某一个特定的分支在计算很多次后才将其分支编译成机器码。

是不是很神奇？有很多种方法来完成计算这部分任务，其中有很多交叉和变种。

选择哪一种策略方式很大一部分取决于性能和可移植型的需要，以及你想要这个语言如何被解释。遍历整个语法树和递归的去计算可能是所有方法中最慢的一种，但是很容易去构建、拓展、思考以及可适配性。

将代码转换的字节码的的编译器在处理字节码上是非常快的，但是创建这种编译器也变得非常复杂和困难。将JIT转换成混合模式也需要你同时支持不同的计算机体系结构，一旦如果你想要解释器同时通过在ARM和x86架构的CPU上。

以上所有的实现方法在现实的编程语言中都能够被找到，大部分时候，实现的方式随着编程语言的发展而改变，Ruby就是很好的例子。在1.8以及之前的版本，Ruby的解释器是树遍历的，边遍历抽象语法树边执行，但是从1.9版本开始变成虚拟机架构，现在Ruby解释器解析源代码，构建抽象语法树然后将抽象语法树编译成字节码，并在虚拟机中执行，这一点咋性能上有了很大的提高。

WebKit Javascript的引擎 JavaScriptCore 和它的叫Squirrelfish同样采用抽象语法树遍历和执行的方式，在2008年之后转向了虚拟机和字节码解释。现在该引擎拥有4各部不同阶段的JIT编译，为了取得很好性能上的表现，在不同的阶段对程序进行不同形式的解释。

另一个例子就是Lua， 主要的实现方式是将其编译成字节码，然后在一个寄存器为基础的虚拟机上执行，在12年后，LuaJIT作为另外一种实现实现方式出现了。LuaJIT的实现者 Mike Pall的目标是创建一个尽可能快的Lua编译器。事实同样如此，通过JIT的方式将繁琐的字节码格式转换成不同基础架构的机器码，从各个性能测试来看，LuaJIT比原生的Lua解释器要快，而且不仅仅是一点点快，有时至少快50倍。

所以所有编译器都是从很小的改进空间开始，这也是我们开始要做的原因。有很多方法来构建更快的解释器，但是将不会很容易理解，在这里我们将理解和开始着手构建。
